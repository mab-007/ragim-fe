import { ChatSession } from "@google/generative-ai";
import { Journal } from "../entity/journal.entity";
import modelFactory from "../factory/model.factory";
import journalRepository from "../repository/journal.repository";
import { CreateJournalObj, UpdateJournalEntry } from "../types/journal.types";
import geminiModelService from "./ModelService/gemini.model.service";
import xenovaEmbeddingModelService from "./ModelService/xenova.embedding.model.service";

class JournalService {

    public async saveUserPromptAndResonse(prompt: string, isQues: Boolean) : Promise<Journal> {
        const query_vector = await this.promptEmbedding(prompt);
        const obj : CreateJournalObj = {
            user_id: 'test-user',
            user_query: prompt,
            user_query_vector: query_vector,
            user_query_vector_dimension: 'float32',
            embedding_algorithm: 'text-embedding-002',
            is_question: isQues
        }
        const res = await journalRepository.createJournalEntry(obj);
        return res;
    }

    public async updateResponsePrompt(resPrompt: string | null, id: string, err?: any) : Promise<Boolean> {
        try {
            if(err){
                throw new Error(err);
            }
            if(!resPrompt)
                throw new Error('Response generated by llm is null');
            const query_vector = await this.promptEmbedding(resPrompt);
            const obj : UpdateJournalEntry = {
                id: id,
                llm_res: resPrompt,
                llm_res_vector: query_vector
            }
            return !! await journalRepository.udpateJournalEntry(obj);
        } catch(err) {
            const obj : UpdateJournalEntry = {
                id: id,
                llm_res: resPrompt,
                error_message: err
            }
            return !! await journalRepository.udpateJournalEntry(obj);
        }
    }

    private async promptEmbedding(prompt: string) : Promise<Array<number>> {
        try {
            const query_vector = await xenovaEmbeddingModelService.getEmbedding(prompt);
            //const query_vector = await geminiModelService.embedPrompt(prompt);
            return query_vector;
        }catch(err) {
            console.log('Error in embedding the string' + err);
            throw new Error(`Error in embedding: ${err}`);
        }
    }

    public async fetchPromptContext(prompt: string) : Promise<Array<Journal>> {
        const query_vector = await this.promptEmbedding(prompt);
        const result = await journalRepository.fetchByQueryVector('test-user', prompt, query_vector);
        return result;
    }

    public async generateResponse(prompt: string, context?: Array<string>) : Promise<string | null> {
        if(context)
            return await geminiModelService.generateRespWithContextFlashOnePointFive(prompt, context);
        return await geminiModelService.generateRespFlashOnePointFive(prompt);
    }

    public async chatSession() : Promise<ChatSession> {
        const model = await modelFactory.getModel('geminiFlash');
        const session = model.startChat();
        session._history = [];
        return session;
    }

}

export default new JournalService();